#生成聊天回复
为给定的聊天对话创建模型响应。

**请求主体**
|名称|类型|描述|
|--|--|--|
|model|string|要使用的模型ID。请参阅模型接口兼容性表了解哪些模型适用于Chat API。|
|n|number|为每条输入消息生成多少个聊天完成选项。请注意，您将根据所有选项生成的令牌数量被收费。将 n 保持为 1 以减少成本。|
|temperature|number|范围在0到2之间。较高的值（如0.8）将使输出更随机，而较低的值（如0.2）将使其更专注和确定性。我们通常建议更改这个值或 top_p，但不要同时更改。|
|messages*|array|构成对话的消息列表。|
|max_tokens|number|在聊天完成中生成的最大令牌数量。|
|presence_penalty|number|数值范围在-2.0到2.0之间。正值会根据文本中出现的频率惩罚新令牌，从而增加模型谈论新话题的可能性。|
|frequency_penalty|number|数值范围在-2.0到2.0之间。正值会根据新令牌在文本中已有的频率进行惩罚，减少模型逐字重复同一行的可能性。|
|user|string|暂不支持|
|top_p|number|一种替代温度采样的方法，称为“核采样”（nucleus sampling），模型会考虑具有 top_p 概率质量的令牌结果。因此，0.1意味着只考虑构成前10%概率质量的令牌。我们通常建议更改这个值或 temperature，但不要同时更改两者。|
|logit_bias|map|修改特定令牌出现在生成内容中的可能性。接受一个将令牌（由其在分词器中的令牌ID指定）映射到偏差值的JSON对象。偏差值范围从-100到100。数学上，偏差会在模型生成logits之前被添加到logits中。具体效果会因模型而异，但介于-1到1之间的值应会减少或增加选择的可能性；而值如-100或100应会导致相关令牌被禁用或被唯一选择。|
|response_format|object|一个指定模型必须输出格式的对象。兼容GPT-4 Turbo和所有比gpt-3.5-turbo-1106更新的GPT-3.5 Turbo模型。将其设置为 { "type": "json_object" } 启用JSON模式，这保证了模型生成的消息是有效的JSON。重要提示：在使用JSON模式时，你还必须通过系统或用户消息指示模型自行生成JSON。如果没有这样做，模型可能会生成无尽的空白流，直到生成达到令牌限制，导致请求长时间运行并且看似“卡住”。还需注意，如果finish_reason="length"，则消息内容可能会被部分截断，这表明生成内容超出了max_tokens限制或对话超出了最大上下文长度。|
|seed|null, integer|此功能处于Beta阶段。如果指定，我们的系统将尽最大努力进行确定性采样，使得使用相同的seed和参数的重复请求应返回相同的结果。确定性不被保证，你应该参考system_fingerprint响应参数以监控后端的变化。|
|stop|string, array, null|最多指定4个序列，当API生成这些序列时将停止生成进一步的令牌。|
|stream|boolean, null|如果设置，将发送部分消息增量，如同在ChatGPT中一样。令牌将作为仅数据的服务器发送事件在它们可用时发送，文字流以 data: [DONE] 消息终止。|
|tools|array|模型可能调用的一组工具。目前仅支持函数作为工具。使用此功能提供模型可能生成JSON输入的函数列表。|
|tool_choice|string or object|控制模型调用哪个（如果有）函数。none 表示模型不会调用任何函数，而是生成一条消息。auto 表示模型可以在生成消息或调用函数之间进行选择。通过 {"type": "function", "function": {"name": "my_function"}} 指定一个特定函数会强制模型调用该函数。none 是没有函数时的默认值。auto 是有函数时的默认值。|
|functions|array|不推荐使用 - 模型可能生成JSON输入的函数列表。|
|function_call|string or object|不推荐使用 - 控制模型调用哪个（如果有）函数。none 表示模型不会调用任何函数，而是生成一条消息。auto 表示模型可以在生成消息或调用函数之间进行选择。通过 {"name": "my_function"} 指定一个特定函数会强制模型调用该函数。none 是没有函数时的默认值。auto 是有函数时的默认值。|
